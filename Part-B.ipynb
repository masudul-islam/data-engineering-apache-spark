{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a319761-45b2-4e76-881c-4d635e430cba",
   "metadata": {},
   "source": [
    "# Section B - Working with DataFrames and SQL\n",
    "### B.1 Load the CSV file from HDFS, and call show() to verify the data is loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf64c765-0cc8-4ab3-8a10-5d9954c38292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "|Ticket number|          Issue Date|Issue time|Meter Id|Marked Time|RP State Plate|Plate Expiry Date| VIN|Make|Body Style|Color|            Location|Route|Agency|Violation code|Violation Description|Fine amount| Latitude|Longitude|Agency Description|Color Description|Body Style Description|\n",
      "+-------------+--------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "|   1103341116|2015-12-21T00:00:...|      1251|    NULL|       NULL|            CA|           200304|NULL|HOND|        PA|   GY|     13147 WELBY WAY|01521|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1103700150|2015-12-21T00:00:...|      1435|    NULL|       NULL|            CA|           201512|NULL| GMC|        VN|   WH|       525 S MAIN ST| 1C51|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1104803000|2015-12-21T00:00:...|      2055|    NULL|       NULL|            CA|           201503|NULL|NISS|        PA|   BK|       200 WORLD WAY|  2R2|     2|          8939|           WHITE CURB|         58|6439997.9|1802686.4|              NULL|             NULL|                  NULL|\n",
      "|   1104820732|2015-12-26T00:00:...|      1515|    NULL|       NULL|            CA|             NULL|NULL|ACUR|        PA|   WH|       100 WORLD WAY| 2F11|     2|           000|               17104h|       NULL|6440041.1|1802686.2|              NULL|             NULL|                  NULL|\n",
      "|   1105461453|2015-09-15T00:00:...|       115|    NULL|       NULL|            CA|           200316|NULL|CHEV|        PA|   BK|  GEORGIA ST/OLYMPIC|1FB70|     1|         8069A| NO STOPPING/STANDING|         93|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1106226590|2015-09-15T00:00:...|        19|    NULL|       NULL|            CA|           201507|NULL|CHEV|        VN|   GY|  SAN PEDRO S/O BOYD|1A35W|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1106500452|2015-12-17T00:00:...|      1710|    NULL|       NULL|            CA|           201605|NULL|MAZD|        PA|   BL|     SUNSET/ALVARADO|00217|     1|          8070| PARK IN GRID LOCK ZN|        163|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1106500463|2015-12-17T00:00:...|      1710|    NULL|       NULL|            CA|           201602|NULL|TOYO|        PA|   BK|     SUNSET/ALVARADO|00217|     1|          8070| PARK IN GRID LOCK ZN|        163|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1106506402|2015-12-22T00:00:...|       945|    NULL|       NULL|            CA|           201605|NULL|CHEV|        PA|   BR|      721 S WESTLAKE| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1106506413|2015-12-22T00:00:...|      1100|    NULL|       NULL|            CA|           201701|NULL|NISS|        PA|   SI|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1106506424|2015-12-22T00:00:...|      1100|    NULL|       NULL|            CA|           201511|NULL|FORD|        TR|   WH|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1106506435|2015-12-22T00:00:...|      1105|    NULL|       NULL|            CA|           201701|NULL|CHRY|        PA|   GO|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1106506446|2015-12-22T00:00:...|      1110|    NULL|       NULL|            CA|           201511|NULL| BMW|        PA|   BK|      1200 W MIRAMAR| 2A75|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1106549754|2015-12-15T00:00:...|       825|    NULL|       NULL|            CA|           201607|NULL|PTRB|        TR|   BK|           4TH/STATE| CM96|     1|         8069A| NO STOPPING/STANDING|         93|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1107179581|2015-12-27T00:00:...|      1055|    NULL|       NULL|            CA|           201605|NULL|TOYO|        PA|   BK|3100 N HOLLYRIDGE DR| NULL|    54|         8058L|         PREF PARKING|         68|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1107179592|2015-12-27T00:00:...|      1200|    NULL|       NULL|            CA|           201602|NULL|MBNZ|        PA|   BK|   3115 N BERENDO DR| NULL|    54|         8058L|         PREF PARKING|         68|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1107179603|2015-12-27T00:00:...|      1400|    NULL|       NULL|            CA|           201611|NULL|NISS|        PA|   WH| 3100 N BEACHWOOD DR| NULL|    54|         8058L|         PREF PARKING|         68|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1107539823|2015-09-16T00:00:...|      2120|    NULL|       NULL|            CA|           201502|NULL|NISS|        PA| NULL|      BLAINE/11TH PL|1FB95|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1107539834|2015-09-16T00:00:...|      1045|    NULL|       NULL|            CA|             NULL|NULL|CHEV|        PA|   BK|  1246 S FIGUEROA ST| 1L20|     1|        8069AP|     NO STOP/STAND PM|         93|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "|   1107780811|2015-12-22T00:00:...|      1102|    NULL|       NULL|            CA|           201606|NULL|HOND|        PA|   BK|       PLATA/RAMPART|  2A1|     1|         8069B|           NO PARKING|         73|    99999|    99999|              NULL|             NULL|                  NULL|\n",
      "+-------------+--------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://192.168.2.250:7077\") \\\n",
    "    .appName(\"MasudulIslam\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.driver.port\", \"9999\") \\\n",
    "    .config(\"spark.blockManager.port\", \"10005\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", \"true\") \\\n",
    "    .config(\"spark.shuffle.service.enabled\", \"false\") \\\n",
    "    .config(\"spark.dynamicAllocation.executorIdleTimeout\", \"30s\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Initialize Spark Context from the Spark Session\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Path to the CSV file in HDFS\n",
    "csv_file_path = \"hdfs://192.168.2.250:9000/parking-citations.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "parking_citations_df = spark.read.option(\"header\", \"true\").csv(csv_file_path)\n",
    "\n",
    "# Show the first few rows to verify it's loaded correctly\n",
    "parking_citations_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0582d14-2fdd-4e58-b2ad-305c70711d83",
   "metadata": {},
   "source": [
    "### B.2 Print the schema for the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc757d7b-dd19-4f39-90e6-2b95fb0f95ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ticket number: string (nullable = true)\n",
      " |-- Issue Date: string (nullable = true)\n",
      " |-- Issue time: string (nullable = true)\n",
      " |-- Meter Id: string (nullable = true)\n",
      " |-- Marked Time: string (nullable = true)\n",
      " |-- RP State Plate: string (nullable = true)\n",
      " |-- Plate Expiry Date: string (nullable = true)\n",
      " |-- VIN: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Route: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Violation code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- Fine amount: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- Agency Description: string (nullable = true)\n",
      " |-- Color Description: string (nullable = true)\n",
      " |-- Body Style Description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the DataFrame\n",
    "parking_citations_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd3c9b-e7c4-49bf-80a3-4e4af8e4c64c",
   "metadata": {},
   "source": [
    "### B.3 Count the number of rows in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7264356c-6d81-4234-8881-1c9fccb229d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=================================================>       (14 + 2) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows in the CSV file: 13077724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the number of rows in the DataFrame\n",
    "row_count = parking_citations_df.count()\n",
    "print(f\"The number of rows in the CSV file: {row_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ccda0c-b16a-444f-825f-ad1eccb40833",
   "metadata": {},
   "source": [
    "### B.4 Count the number of partitions in the underlying RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f997f7a-7b49-475c-83a6-f76f58b13367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of partitions in the underlying RDD: 16\n"
     ]
    }
   ],
   "source": [
    "# Count the number of partitions in the underlying RDD\n",
    "partitions_count = parking_citations_df.rdd.getNumPartitions()\n",
    "print(f\"The number of partitions in the underlying RDD: {partitions_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da26a1f-42c2-4cb0-9d86-9eff7eb0777f",
   "metadata": {},
   "source": [
    "### B.5 Drop the columns VIN, Latitude and Longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccda8c7c-99ba-4347-8b8c-838d515972ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns\n",
    "parking_citations_df = parking_citations_df.drop(\"VIN\", \"Latitude\", \"Longitude\")\n",
    "\n",
    "# Check the schema of the DataFrame to ensure that the VIN, Latitude, and Longitude have been removed or not\n",
    "parking_citations_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b54725c-00f6-4af6-9407-d970ff2ec6db",
   "metadata": {},
   "source": [
    "### B.6 Find the maximum fine amount. How many fines have this amount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85d7e3e1-844f-40ff-be18-38a82465c975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum fine amount is: 1100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fines with the maximum amount: 626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, max\n",
    "\n",
    "# Convert the 'Fine amount' column to float\n",
    "parking_citations_df = parking_citations_df.withColumn(\"Fine amount\", col(\"Fine amount\").cast(\"float\"))\n",
    "\n",
    "# Find the maximum fine amount\n",
    "max_fine_amount = parking_citations_df.select(max(\"Fine amount\")).collect()[0][0]\n",
    "print(f\"The maximum fine amount is: {max_fine_amount}\")\n",
    "\n",
    "# Count how many fines have this amount\n",
    "max_fine_count = parking_citations_df.filter(col(\"Fine amount\") == max_fine_amount).count()\n",
    "print(f\"Number of fines with the maximum amount: {max_fine_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9148330c-e614-4cfd-b26b-c1a0b4dbbee5",
   "metadata": {},
   "source": [
    "### B.7 Show the top 20 most frequent vehicle makes, and their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0810c5f3-0576-4aea-b306-0f68496e68e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|Make|  count|\n",
      "+----+-------+\n",
      "|TOYT|2150768|\n",
      "|HOND|1479996|\n",
      "|FORD|1116235|\n",
      "|NISS| 945133|\n",
      "|CHEV| 892676|\n",
      "| BMW| 603092|\n",
      "|MERZ| 543298|\n",
      "|VOLK| 432030|\n",
      "|HYUN| 404917|\n",
      "|DODG| 391686|\n",
      "|LEXS| 368420|\n",
      "| KIA| 328155|\n",
      "|JEEP| 316300|\n",
      "|AUDI| 255395|\n",
      "|MAZD| 242344|\n",
      "|OTHR| 205546|\n",
      "| GMC| 184889|\n",
      "|INFI| 174315|\n",
      "|CHRY| 159948|\n",
      "|SUBA| 154640|\n",
      "+----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Group by 'Make' and count the occurrences, then order by count in descending order\n",
    "top_vehicle_makes = parking_citations_df.groupBy(\"Make\").count().orderBy(\"count\", ascending=False).limit(20)\n",
    "top_vehicle_makes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3bbe6-7d04-4d39-8fac-d456022e4785",
   "metadata": {},
   "source": [
    "### B.8 Let’s expand some abbreviations in the color column. Create a User Defined Function tocreate a new column, ‘color long’, mapping the original colors to their corresponding values in the dictionary below. If there is no key matching the original color, use the original color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5f82f80-bf63-410b-9b7e-8b941e240ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|Color|ColorLong|\n",
      "+-----+---------+\n",
      "|GY   |Gray     |\n",
      "|WH   |White    |\n",
      "|BK   |Black    |\n",
      "|WH   |White    |\n",
      "|BK   |Black    |\n",
      "|GY   |Gray     |\n",
      "|BL   |Blue     |\n",
      "|BK   |Black    |\n",
      "|BR   |Brown    |\n",
      "|SI   |Silver   |\n",
      "|WH   |White    |\n",
      "|GO   |Gold     |\n",
      "|BK   |Black    |\n",
      "|BK   |Black    |\n",
      "|BK   |Black    |\n",
      "|BK   |Black    |\n",
      "|WH   |White    |\n",
      "|NULL |NULL     |\n",
      "|BK   |Black    |\n",
      "|BK   |Black    |\n",
      "+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Define the full color mapping dictionary\n",
    "COLORS = {\n",
    "    'AL': 'Aluminum', 'AM': 'Amber', 'BG': 'Beige', 'BK': 'Black',\n",
    "    'BL': 'Blue', 'BN': 'Brown', 'BR': 'Brown', 'BZ': 'Bronze',\n",
    "    'CH': 'Charcoal', 'DK': 'Dark', 'GD': 'Gold', 'GO': 'Gold',\n",
    "    'GN': 'Green', 'GY': 'Gray', 'GT': 'Granite', 'IV': 'Ivory',\n",
    "    'LT': 'Light', 'OL': 'Olive', 'OR': 'Orange', 'MR': 'Maroon',\n",
    "    'PK': 'Pink', 'RD': 'Red', 'RE': 'Red', 'SI': 'Silver', 'SL': 'Silver',\n",
    "    'SM': 'Smoke', 'TN': 'Tan', 'VT': 'Violet', 'WT': 'White', 'WH': 'White',\n",
    "    'YL': 'Yellow', 'YE': 'Yellow', 'UN': 'Unknown'\n",
    "}\n",
    "\n",
    "# Define a UDF to map color abbreviations to full color names\n",
    "def expand_color_abbr(color_abbr):\n",
    "    return COLORS.get(color_abbr, color_abbr)\n",
    "\n",
    "# Register the UDF with Spark\n",
    "expand_color_udf = udf(expand_color_abbr, StringType())\n",
    "\n",
    "# Create the new 'color_long' column using the UDF\n",
    "parking_citations_df = parking_citations_df.withColumn(\"ColorLong\", expand_color_udf(col(\"Color\")))\n",
    "\n",
    "# Display the DataFrame to verify the new column\n",
    "parking_citations_df.select(\"Color\", \"ColorLong\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5174c-f237-4419-9acd-2c9587e3d7dc",
   "metadata": {},
   "source": [
    "### B.9 Using this new column, what’s the most frequent colour value for Toyotas (TOYT)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d4109b7-ae38-48e4-a9ec-106d5f8972b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent color for Toyotas is: Gray with 489697 occurrences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Filter for Toyotas, group by the expanded color, and count the occurrences\n",
    "top_toyota_color = parking_citations_df.filter(col(\"Make\") == \"TOYT\")\\\n",
    "                                      .groupBy(\"ColorLong\")\\\n",
    "                                      .count()\\\n",
    "                                      .orderBy(\"count\", ascending=False)\\\n",
    "                                      .first()\n",
    "\n",
    "print(f\"The most frequent color for Toyotas is: {top_toyota_color['ColorLong']} with {top_toyota_color['count']} occurrences\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
